{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Using H1st.AI to Encode Human Insights as a Model and Harmonize Human + ML in a H1st.Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Use case analysis: turning on safe-mode vs post-moterm analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The H1ST.AI approach to this problem begins by thinking about the end-users of the decision system, and their uses cases.\n",
    "\n",
    "What are the use cases for such Automotive Cybersecurity system? We can envision two distinctive use cases:\n",
    "  1. The onboard intrusion detection system can detect an attack event in realtime and set the car into a safe mode so that drivers can safely get to a safe location and not be stuck in the highway with malfunctioning cars.\n",
    "  2. An security expert could review the attack in post-mortem mode, in which the IDS provides message-by-message attack vs normal classification.\n",
    "\n",
    "For use case #1 \"safe mode triggering by attack event detection\", the ML requirement is that it has near-zero FPR. \n",
    "\n",
    "To give an example, each second might contain 100 of CAN messages per car. If we have a fleet with just 1000 cars, each driven 1h per day, then a FPR of 0.001% at message-level still means that each day we have 0.00001 x 100msg x 3600s x 1000cars = 3600 false positive events per day that a security operation center will need to handle!\n",
    "\n",
    "Additionally, for deployment & anticipated regulatory purpose, the system should behave robustly and explainably. While explainability is a complex subject, we meant that one could anticipate the system’s behavior reasonably well, as well as for legal/regulation purposes. As we saw with iForest or GBM ML models, they don’t quite meet this requirement, as it is hard to explain precisely how these models classify attacks, even if they can achieve good accuracy.\n",
    "\n",
    "For use case #2 \"post-morterm analysis\", it turns out that the requirement is very different. Some FPR could be traded off for higher TPR for post-mortem. And the system might not need to highly explainable as it is after all the jobs of the security experts to analyze the attacks in depth and make the final decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Problem (re)formulation into H1st.AI Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reformulate the problem into the form of a decision graph, where the outermost flow detects attack events and corresponding yes branches handles message classification. For this tutorial we focus on injection attacks which are most common in the wild (we will revisit this later).\n",
    "\n",
    "The graph looks like this.\n",
    "\n",
    "<img src=\"https://h1st-static.s3.amazonaws.com/graph2.png\" alt=\"automotive cybersecurity solution graph\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. Encoding human insights for event detection as a H1st.Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember when we start analyzing the CAN dataset, we have remarked that the normal data is highly regular, especially in terms of the message frequency for each CAN ID.\n",
    "\n",
    "It turns out that using message frequency statistics for injection event detection is highly accurate for safe-mode use cases (high TPR, low FNR). This surprising fact was first pointed out by the original CAN bus hackers Chris Valasek and Charlie Miller in the seminal white paper [Adventures in Automotive Networks and Control Units](https://ioactive.com/pdfs/IOActive_Adventures_in_Automotive_Networks_and_Control_Units.pdf).\n",
    "\n",
    "> It is pretty straightforward to detect the attacks discussed in this paper.  They always involve either sending new, unusual CAN packets or flooding the CAN bus with common packets... Additionally, the frequency of normal CAN packets is very predictable... Therefore we propose that a system can detect CAN anomalies based on the known frequency of certain traffic and can alert a system or user if frequency levels vary drastically from what is well known. \n",
    "\n",
    "Using H1ST, we can encode insights of such “human” models and use them just like ML models. An h1.Model is essentially anything that can predict. H1ST provides tools to help automate their saving and loading, too, easing the way for using them in an integrated decision system.\n",
    "\n",
    "A data-science project in H1ST.AI is designed to be a Python-importable package. You can create such a project using the `h1` command-line tool.\n",
    "\n",
    "Organizing model code this way makes it easy to use. The Model API is uniquely designed so that models can be used interactively in notebooks as well as in more complex project such as this one.\n",
    "\n",
    "```{note}\n",
    "The H1st package of the full tutorial is available from the H1st Github project at [https://github.com/h1st-ai/h1st/tree/master/examples/AutoCyber](https://github.com/h1st-ai/h1st/tree/master/examples/AutoCyber).\n",
    "\n",
    "Simply go ahead and clone it, then follow along.\n",
    "```\n",
    "\n",
    "The details of training the message frequency statistics is quite simple: looping through a number of files to compute window statistics such as how many msg per CAN ID are found & what’s the min & max and percentile values.\n",
    "\n",
    "The content of `models/msg_freq_event_detector.py` should look like following. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import h1st as h1\n",
    "\n",
    "import config\n",
    "import util\n",
    "\n",
    "class MsgFreqEventDetectorModel(h1.RuleBasedModel):\n",
    "    def load_data(self, num_files=None):\n",
    "        return util.load_data(num_files, shuffle=False)\n",
    "    \n",
    "    def train(self, prepared_data):\n",
    "        files = prepared_data[\"normal_files\"]\n",
    "        \n",
    "        from collections import defaultdict\n",
    "        def count_messages(f):\n",
    "            df = pd.read_parquet(f)\n",
    "            counts = defaultdict(list)\n",
    "            \n",
    "            for window_start in util.gen_windows(df, window_size=config.WINDOW_SIZE, step_size=config.WINDOW_SIZE):\n",
    "                w_df = df[(df.Timestamp >= window_start) & (df.Timestamp < window_start + config.WINDOW_SIZE)]\n",
    "                for sensor in config.SENSORS:\n",
    "                    counts[sensor].append(len(w_df.dropna(subset=[sensor])))\n",
    "\n",
    "            return pd.DataFrame(counts)\n",
    "        \n",
    "        ret = [count_messages(f) for f in files]\n",
    "        df = pd.concat(ret)\n",
    "\n",
    "        self.stats = df.describe()\n",
    "    \n",
    "    def predict(self, data):\n",
    "        df = data['df']\n",
    "        window_starts = data[\"window_starts\"]\n",
    "        window_results = []\n",
    "        for window_start in window_starts:\n",
    "            w_df = df[(df.Timestamp >= window_start) & (df.Timestamp < window_start + config.WINDOW_SIZE)]\n",
    "            results = {}\n",
    "            for _, sensor in enumerate(config.SENSORS):\n",
    "                w_df_sensor = w_df.dropna(subset=[sensor])\n",
    "                max_normal_message_freq = self.stats.at['max', sensor]\n",
    "                msg_freq = len(w_df_sensor)\n",
    "                if msg_freq > (max_normal_message_freq * 1.1):\n",
    "                    results[sensor] = 1\n",
    "                else:\n",
    "                    results[sensor] = 0\n",
    "                # print(\"%s => %s\" % ((window_start, sensor, msg_freq, max_normal_message_freq), results[sensor]))\n",
    "                results[\"WindowInAttack\"] = any(results.values())\n",
    "            results[\"window_start\"] = window_start # information for down-stream\n",
    "            window_results.append(results)\n",
    "        return {\"event_detection_results\": window_results}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import and train this `MsgFreqEventDetectorModel`.\n",
    "\n",
    "Using h1st.Model enable ease of saving/loading them. By default, the \"model\", \"stats\" and \"metrics\" properties are persisted and they support a variety of flavors & data structure.\n",
    "\n",
    "```{note}\n",
    "We call `h1.init()` to setup the model repository with storage location specified in `MODEL_REPO_PATH`.\n",
    "You can also use put `MODEL_REPO_PATH` in `config.py` and call `h1.init()` without any parameter.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This sets up the H1st model repository.\n",
    "h1.init(MODEL_REPO_PATH = \"models\")\n",
    "\n",
    "from msg_freq_event_detector import MsgFreqEventDetectorModel\n",
    "\n",
    "m = MsgFreqEventDetectorModel()\n",
    "\n",
    "# Using several long trips is sufficient to compute freq stats at sub-second window level for each car model\n",
    "data = m.load_data(num_files=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should take several minutes to compute the regular frequency a.k.a. \"train\" this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.train(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SteeringAngle</th>\n",
       "      <th>CarSpeed</th>\n",
       "      <th>YawRate</th>\n",
       "      <th>Gx</th>\n",
       "      <th>Gy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11084.000000</td>\n",
       "      <td>11084.000000</td>\n",
       "      <td>11084.000000</td>\n",
       "      <td>11084.000000</td>\n",
       "      <td>11084.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>34.316763</td>\n",
       "      <td>17.158607</td>\n",
       "      <td>34.314778</td>\n",
       "      <td>34.314778</td>\n",
       "      <td>34.314778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.311491</td>\n",
       "      <td>2.121101</td>\n",
       "      <td>1.359257</td>\n",
       "      <td>1.359257</td>\n",
       "      <td>1.359257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SteeringAngle      CarSpeed       YawRate            Gx            Gy\n",
       "count   11084.000000  11084.000000  11084.000000  11084.000000  11084.000000\n",
       "mean       34.316763     17.158607     34.314778     34.314778     34.314778\n",
       "std         1.311491      2.121101      1.359257      1.359257      1.359257\n",
       "min         0.000000      0.000000      0.000000      0.000000      0.000000\n",
       "25%        33.000000     17.000000     33.000000     33.000000     33.000000\n",
       "50%        34.000000     17.000000     34.000000     34.000000     34.000000\n",
       "75%        35.000000     18.000000     35.000000     35.000000     35.000000\n",
       "max        40.000000     22.000000     41.000000     41.000000     41.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persisting returns a model version ID that you can use to load it back later, (or you can also give it name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-15 15:20:56,427 INFO h1st.model_repository.model_repository: Saving stats property...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'01EMQ5M4Q9M9EP1YTY6804JMQ8'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d. Working with H1st Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now make some event-level predictions.\n",
    "\n",
    "Note that since the model was persisted using H1st model repo, this means that we can easily come back to a notebooks and/or scripts and load the trained model or computed statistics.\n",
    "\n",
    "Importantly, H1st allows much speedier integration into a Graph (and later deployment, too)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/attack-samples/20181116_Driver1_Trip4-1.parquet'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['attack_files'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-15 15:20:56,455 INFO h1st.model_repository.model_repository: Loading version 01EMQ5M4Q9M9EP1YTY6804JMQ8 ....\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['window_starts', 'event_detection_results'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from graph import WindowGenerator\n",
    "from msg_freq_event_detector import MsgFreqEventDetectorModel\n",
    "\n",
    "graph = h1.Graph()\n",
    "graph.start()\\\n",
    "     .add(WindowGenerator())\\\n",
    "     .add(MsgFreqEventDetectorModel().load())\n",
    "graph.end()\n",
    "\n",
    "df = pd.read_parquet(data['attack_files'][0])\n",
    "\n",
    "results = graph.predict({\"df\": df})\n",
    "results.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we should see that we can start detecting attacks events. We'll evaluate this later, and now let's finish adding our detection graph by adding the message classifier.\n",
    "\n",
    "Note that the graph returns separate output keys, collected from all the nodes's outputs. Typically each node is expected to return a dict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3e. Adding a message classifier, harmonizing human + ML models in the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For message-level classification we can simply bring back our gradient-boosted trees which did a decent job of recognizing injection messages. (Integrating sequence model such as Bidirectional LSTM is left as an exercise for the reader).\n",
    "\n",
    "As before, we've re-orgarnized it as a H1st.Model in the tutorial folder, ready for use. \n",
    "\n",
    "The content of `models/gradient_boosting_msg_classifier.py` looks like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h1st as h1\n",
    "import pandas as pd\n",
    "\n",
    "import config\n",
    "import util\n",
    "\n",
    "FEATURES = config.SENSORS + [\"%s_TimeDiff\" % s for s in config.SENSORS]\n",
    "\n",
    "class GradientBoostingMsgClassifierModel(h1.MLModel):\n",
    "    def load_data(self, num_files=None):\n",
    "        return util.load_data(num_files, shuffle=False)\n",
    "\n",
    "    def prep(self, data):\n",
    "        def concat_processed_files(files):\n",
    "            dfs = []\n",
    "            for f in files:\n",
    "                z = pd.read_parquet(f)\n",
    "                z = util.compute_timediff_fillna(z, dropna_subset=FEATURES)\n",
    "                dfs.append(z)\n",
    "            df2 = pd.concat(dfs)\n",
    "            return df2\n",
    "        split = int(len(data[\"attack_files\"])*0.5)\n",
    "        train_files = data[\"attack_files\"][:split]\n",
    "        test_files = data[\"attack_files\"][split:]\n",
    "        result = {\n",
    "            \"train_files\": train_files,\n",
    "            \"test_files\": test_files,\n",
    "            \"train_attack_df\": concat_processed_files(train_files),\n",
    "            \"test_attack_df\": concat_processed_files(test_files)\n",
    "        }\n",
    "        print(\"len train_attack_df = %s\" % len(result[\"train_attack_df\"]))\n",
    "        print(\"len test_attack_df = %s\" % len(result[\"test_attack_df\"]))\n",
    "        return result\n",
    "\n",
    "    def train(self, prepared_data):\n",
    "        df = prepared_data[\"train_attack_df\"]\n",
    "        from sklearn.experimental import enable_hist_gradient_boosting\n",
    "        from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "        X = df[FEATURES]\n",
    "        y = df.Label == config.ATTACK_LABEL\n",
    "        self.base_model = HistGradientBoostingClassifier(max_iter=500).fit(X, y)\n",
    "\n",
    "    def evaluate(self, prepared_data):\n",
    "        df = prepared_data[\"test_attack_df\"]\n",
    "        ypred = self.base_model.predict(df[FEATURES])\n",
    "        import sklearn.metrics\n",
    "        cf = sklearn.metrics.confusion_matrix(df.Label == config.ATTACK_LABEL, ypred)\n",
    "        acc = sklearn.metrics.accuracy_score(df.Label == config.ATTACK_LABEL, ypred)\n",
    "        print(cf)\n",
    "        print(\"Accuracy = %.4f\" % acc)\n",
    "        self.metrics = {\"confusion_matrix\": cf, \"accuracy\": acc}\n",
    "    \n",
    "    def predict(self, data):\n",
    "        df = data[\"df\"].copy()\n",
    "        df = util.compute_timediff_fillna(df)\n",
    "        df['MsgIsAttack'] = 0\n",
    "        df['WindowInAttack'] = 0\n",
    "        for event_result in data[\"event_detection_results\"]:\n",
    "            if event_result['WindowInAttack']:\n",
    "                # print(\"window %s in attack: event_result = %s\" % (event_result['window_start'], event_result))\n",
    "                in_window = (df.Timestamp >= event_result['window_start']) & (df.Timestamp < event_result['window_start'] + config.WINDOW_SIZE)\n",
    "                w_df = df[in_window]\n",
    "                if len(w_df) > 0:\n",
    "                    ypred = self.base_model.predict(w_df[FEATURES])\n",
    "                    df.loc[in_window, \"WindowInAttack\"] = 1\n",
    "                    df.loc[in_window, \"MsgIsAttack\"] = ypred.astype(int)\n",
    "        return {\"injection_window_results\": df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradient_boosting_msg_classifier import GradientBoostingMsgClassifierModel\n",
    "\n",
    "m2 = GradientBoostingMsgClassifierModel()\n",
    "data = m2.load_data(num_files=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train_attack_df = 1030994\n",
      "len test_attack_df = 868436\n"
     ]
    }
   ],
   "source": [
    "prepared_data = m2.prep(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>SteeringAngle</th>\n",
       "      <th>CarSpeed</th>\n",
       "      <th>YawRate</th>\n",
       "      <th>Gx</th>\n",
       "      <th>Gy</th>\n",
       "      <th>Label</th>\n",
       "      <th>AttackSensor</th>\n",
       "      <th>AttackMethod</th>\n",
       "      <th>AttackParams</th>\n",
       "      <th>AttackEventIndex</th>\n",
       "      <th>SteeringAngle_TimeDiff</th>\n",
       "      <th>CarSpeed_TimeDiff</th>\n",
       "      <th>YawRate_TimeDiff</th>\n",
       "      <th>Gx_TimeDiff</th>\n",
       "      <th>Gy_TimeDiff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.024343</td>\n",
       "      <td>67.604385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189777</td>\n",
       "      <td>0.002458</td>\n",
       "      <td>-0.002173</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027083</td>\n",
       "      <td>67.608772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189777</td>\n",
       "      <td>0.002458</td>\n",
       "      <td>-0.002173</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.013509</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.037508</td>\n",
       "      <td>67.608772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189665</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>-0.002151</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.013230</td>\n",
       "      <td>0.013230</td>\n",
       "      <td>0.013230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.038148</td>\n",
       "      <td>67.613159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189665</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>-0.002151</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.011065</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.043605</td>\n",
       "      <td>67.617538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189665</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>-0.002151</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.005457</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369439</th>\n",
       "      <td>1649.991996</td>\n",
       "      <td>7.202400</td>\n",
       "      <td>6.485162</td>\n",
       "      <td>0.998420</td>\n",
       "      <td>0.433515</td>\n",
       "      <td>0.138374</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.011372</td>\n",
       "      <td>0.011372</td>\n",
       "      <td>0.011372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369440</th>\n",
       "      <td>1649.994320</td>\n",
       "      <td>7.168000</td>\n",
       "      <td>6.485162</td>\n",
       "      <td>0.998420</td>\n",
       "      <td>0.433515</td>\n",
       "      <td>0.138374</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.012805</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369441</th>\n",
       "      <td>1650.003266</td>\n",
       "      <td>7.168000</td>\n",
       "      <td>6.485162</td>\n",
       "      <td>0.994170</td>\n",
       "      <td>0.437117</td>\n",
       "      <td>0.137005</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.011269</td>\n",
       "      <td>0.011269</td>\n",
       "      <td>0.011269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369442</th>\n",
       "      <td>1650.007432</td>\n",
       "      <td>7.133600</td>\n",
       "      <td>6.485162</td>\n",
       "      <td>0.994170</td>\n",
       "      <td>0.437117</td>\n",
       "      <td>0.137005</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.013111</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369443</th>\n",
       "      <td>1650.009595</td>\n",
       "      <td>7.133600</td>\n",
       "      <td>6.422659</td>\n",
       "      <td>0.994170</td>\n",
       "      <td>0.437117</td>\n",
       "      <td>0.137005</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.024471</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030994 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Timestamp  SteeringAngle  CarSpeed   YawRate        Gx        Gy  \\\n",
       "2          0.024343      67.604385  0.000000  0.189777  0.002458 -0.002173   \n",
       "3          0.027083      67.608772  0.000000  0.189777  0.002458 -0.002173   \n",
       "4          0.037508      67.608772  0.000000  0.189665  0.002375 -0.002151   \n",
       "5          0.038148      67.613159  0.000000  0.189665  0.002375 -0.002151   \n",
       "6          0.043605      67.617538  0.000000  0.189665  0.002375 -0.002151   \n",
       "...             ...            ...       ...       ...       ...       ...   \n",
       "369439  1649.991996       7.202400  6.485162  0.998420  0.433515  0.138374   \n",
       "369440  1649.994320       7.168000  6.485162  0.998420  0.433515  0.138374   \n",
       "369441  1650.003266       7.168000  6.485162  0.994170  0.437117  0.137005   \n",
       "369442  1650.007432       7.133600  6.485162  0.994170  0.437117  0.137005   \n",
       "369443  1650.009595       7.133600  6.422659  0.994170  0.437117  0.137005   \n",
       "\n",
       "         Label AttackSensor AttackMethod  AttackParams  AttackEventIndex  \\\n",
       "2       Normal           NA           NA           0.0              <NA>   \n",
       "3       Normal           NA           NA           0.0              <NA>   \n",
       "4       Normal           NA           NA           0.0              <NA>   \n",
       "5       Normal           NA           NA           0.0              <NA>   \n",
       "6       Normal           NA           NA           0.0              <NA>   \n",
       "...        ...          ...          ...           ...               ...   \n",
       "369439  Normal           NA           NA           0.0              <NA>   \n",
       "369440  Normal           NA           NA           0.0              <NA>   \n",
       "369441  Normal           NA           NA           0.0              <NA>   \n",
       "369442  Normal           NA           NA           0.0              <NA>   \n",
       "369443  Normal           NA           NA           0.0              <NA>   \n",
       "\n",
       "        SteeringAngle_TimeDiff  CarSpeed_TimeDiff  YawRate_TimeDiff  \\\n",
       "2                    -1.000000          -1.000000         -1.000000   \n",
       "3                     0.013509          -1.000000         -1.000000   \n",
       "4                    -1.000000          -1.000000          0.013230   \n",
       "5                     0.011065          -1.000000         -1.000000   \n",
       "6                     0.005457          -1.000000         -1.000000   \n",
       "...                        ...                ...               ...   \n",
       "369439               -1.000000          -1.000000          0.011372   \n",
       "369440                0.012805          -1.000000         -1.000000   \n",
       "369441               -1.000000          -1.000000          0.011269   \n",
       "369442                0.013111          -1.000000         -1.000000   \n",
       "369443               -1.000000           0.024471         -1.000000   \n",
       "\n",
       "        Gx_TimeDiff  Gy_TimeDiff  \n",
       "2         -1.000000    -1.000000  \n",
       "3         -1.000000    -1.000000  \n",
       "4          0.013230     0.013230  \n",
       "5         -1.000000    -1.000000  \n",
       "6         -1.000000    -1.000000  \n",
       "...             ...          ...  \n",
       "369439     0.011372     0.011372  \n",
       "369440    -1.000000    -1.000000  \n",
       "369441     0.011269     0.011269  \n",
       "369442    -1.000000    -1.000000  \n",
       "369443    -1.000000    -1.000000  \n",
       "\n",
       "[1030994 rows x 16 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_data[\"train_attack_df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2.train(prepared_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[832136    345]\n",
      " [ 16438  19517]]\n",
      "Accuracy = 0.9807\n"
     ]
    }
   ],
   "source": [
    "m2.evaluate(prepared_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-15 15:21:59,566 INFO h1st.model_repository.model_repository: Saving metrics property...\n",
      "2020-10-15 15:21:59,567 INFO h1st.model_repository.model_repository: Saving model property...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'01EMQ5P2CCB86K95KR1YW8GSN6'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting everything together in a `h1.Graph` and running through `graph.predict()` on a single file looks like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-15 15:22:02,347 INFO h1st.model_repository.model_repository: Loading version 01EMQ5M4Q9M9EP1YTY6804JMQ8 ....\n",
      "2020-10-15 15:22:02,351 INFO h1st.model_repository.model_repository: Loading version 01EMQ5P2CCB86K95KR1YW8GSN6 ....\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['window_starts', 'event_detection_results', 'injection_window_results'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NoOp(h1.Action):\n",
    "    def call(self, command, inputs):\n",
    "        pass\n",
    "\n",
    "graph = h1.Graph()\n",
    "graph.start()\\\n",
    "     .add(WindowGenerator())\\\n",
    "     .add(h1.Decision(MsgFreqEventDetectorModel().load(),\n",
    "                      decision_field=\"WindowInAttack\",\n",
    "                      result_field=\"event_detection_results\"))\\\n",
    "     .add(yes=GradientBoostingMsgClassifierModel().load(),\n",
    "          no=NoOp())\n",
    "graph.end()\n",
    "\n",
    "results = graph.predict({\"df\": df})\n",
    "results.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix for message-level classification looks like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[354970     28]\n",
      " [   115  15124]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "print(sklearn.metrics.confusion_matrix(results['injection_window_results'][\"Label\"] == \"Attack\", \n",
    "                                       results['injection_window_results'][\"MsgIsAttack\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's evaluate the whole graph against the test set, especially focusing on the event-level TPR & FPR since they are crucial in the safe-mode deployment use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============\n",
      "Event-level confusion matrix\n",
      "[[8567    0]\n",
      " [  22 1083]]\n",
      "Event TPR = 0.9801, FPR = 0.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8567, 0, 22, 1083)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from AutoCyber.util import evaluate_event_graph\n",
    "\n",
    "evaluate_event_graph(graph, prepared_data['test_files'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that's something! Event-level FPR=0.0% with zero false positives!\n",
    "\n",
    "(Note that the provided attack samples was created on a subset of the driving trips, but you should able to do a more thorought evaluation by running against synthetic attacks created from the all driving trips dataset, and the results should be the same: zero false positive at event-level.)\n",
    "\n",
    "The message-level accuracy should be nearly the same because we used the same classifier. However the decomposition leads to separation of concerns and requirement for these two use cases. We're much more comfortable with the solution now both in terms of accuracy as well as robustness and explainability.\n",
    "\n",
    "Another significance worth pointing out here is that we get multiple output streams from H1st.Graph: event-level outputs and msg-level outputs, exactly what we need for two different use cases we highlighted: safe-mode triggering and post-mortem analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
