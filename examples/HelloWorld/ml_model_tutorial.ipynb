{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "The H1st Model is one of the core concepts of H1st, and it is central to the way H1st works. Model presents a uniform interface to its users, whether the underlying model is boolean logic, fuzzy logic derived from humanâ€™s intuition, a Scikit-learn random forest, or a Tensorflow neural network. This makes it possible for you to use and combine Models in Graphs or Ensembles easily.\n",
    "\n",
    "The easiest way to understand H1st model is actually implementing it. H1st model provides all the interfaces to manage the life cycle of the model. \n",
    "\n",
    "Below is an example of how you create a model, prepare data, run training and persist a Scikit-learn based model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets, metrics\n",
    "import h1st as h1\n",
    "\n",
    "class MLModel(h1.MLModel):\n",
    "    def __init__(self):\n",
    "        # This is the native SKLearn model\n",
    "        # H1st can automatically save/load this \"self.model\" property if it's a SKlearn or tf.keras.Model\n",
    "        self.model = svm.SVC(gamma=0.001, C=100.)\n",
    "\n",
    "    def get_data(self):\n",
    "        digits = datasets.load_digits()\n",
    "        return {\n",
    "            \"x\": digits.data,\n",
    "            \"y\": digits.target\n",
    "        }\n",
    "\n",
    "    def explore_data(self, data):\n",
    "        pass\n",
    "\n",
    "    def prep(self, data):\n",
    "        x = data[\"x\"]\n",
    "        y = data[\"y\"]\n",
    "        num_tests = 10\n",
    "        return {\n",
    "            \"train_x\": x[num_tests:],\n",
    "            \"train_y\": y[num_tests:],\n",
    "            \"test_x\": x[0:num_tests],\n",
    "            \"test_y\": y[0:num_tests]\n",
    "        }\n",
    "\n",
    "    def train(self, prepared_data):\n",
    "        self.model.fit(prepared_data[\"train_x\"], prepared_data[\"train_y\"])\n",
    "\n",
    "    def evaluate(self, data):\n",
    "        pred_y = self.predict({\"x\": data[\"test_x\"]})\n",
    "        # self.metrics can also be persisted automatically by H1st\n",
    "        self.metrics = metrics.accuracy_score(data[\"test_y\"], pred_y)\n",
    "        return self.metrics\n",
    "\n",
    "    def predict(self, input_data: dict) -> dict:\n",
    "        \"\"\"\n",
    "        We expect an array of input data rows in the \"x\" field of the input_data dict\n",
    "        \"\"\"\n",
    "        return self.model.predict(input_data[\"x\"])"
   ]
  },
  {
   "source": [
    "To create an H1st model, you can start by create a new class and subclass from the h1.Model.\n",
    "\n",
    "Then we populate the methods to get_data() to get the data, prep() to preprocess, and of course train(), evaluate() and predict().\n",
    "\n",
    "This is how the model is used. Pay close attention to the parameters of the methods and note that the train-val data splitting is done in prep(), and that most `data` parameters should be Python dictionaries where the data scientists can creatively decide how to use the keys & values such as `train_x`, `test_x`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MLModel()\n",
    "raw_data = m.get_data()\n",
    "print(raw_data)\n",
    "\n",
    "prepared_data = m.prep(raw_data)\n",
    "\n",
    "m.train(prepared_data)\n",
    "m.evaluate(prepared_data)\n",
    "print(\"accuracy_score = %.4f\" % m.metrics)"
   ]
  },
  {
   "source": [
    "The beauty of this API is that we can keep same workflow steps for all kinds of models, whether they are boolean/fuzzy logic or ML models!\n",
    "\n",
    "Also note that the H1st Model API is designed to work well both interactive in Jupyter Notebooks and in larger Python project, e.g. we could easily do `from ml_model import MLModel` then use it the same way."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "H1st AI supports out-of-the-box easy persisting & loading of `sklearn` and `tf.keras` models to a model repository (other types can be added).\n",
    "\n",
    "This makes it much easier to include model in larger workflows such as in H1st Graphs or Ensembles. It can enable data science teams to be much more productive.\n",
    "\n",
    "A model repository is simply a folder on local disk or S3. We call `h1.init()` specifying `MODEL_REPO_PATH`. Alternative it can be automatically picked up in the project's `config.py`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1.init(MODEL_REPO_PATH=\".models\")\n",
    "version_id = m.persist()\n",
    "print(\"Persisted to version_id = %s\" % version_id)\n",
    "\n",
    "m = MLModel().load(version_id)\n",
    "print(m.metrics)"
   ]
  }
 ]
}