{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Tutorial on Modelers/Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows how you can create Modeler and Model using the `iris` dataset as an example.\n",
    "Firstly, let's create an `MLModeler` with `load_data` to load the `iris` dataset and generate training data to train a LogisticRegression base model in `train`. The `h1st` framework provides the `build` method which calls `load_data` and `train` and produces the corresponding `MLModel` which you needs to define."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Any, Dict\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from h1st.model.model import Model\n",
    "from h1st.model.ml_modeler import MLModeler\n",
    "from h1st.model.ml_model import MLModel\n",
    "\n",
    "class MyMLModeler(MLModeler):\n",
    "    def __init__(self):\n",
    "        self.stats = {}\n",
    "        self.example_test_data_ratio = 0.2\n",
    "\n",
    "    def load_data(self) -> Dict:\n",
    "        df_raw = datasets.load_iris(as_frame=True).frame\n",
    "        return self.generate_training_data({'df_raw': df_raw})\n",
    "    \n",
    "    def preprocess(self, data):\n",
    "        self.stats['scaler'] = StandardScaler()\n",
    "        return self.stats['scaler'].fit_transform(data) \n",
    "    \n",
    "    def generate_training_data(self, data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        df_raw = data['df_raw']\n",
    "        df_raw.columns = ['sepal_length','sepal_width','petal_length','petal_width', 'species']\n",
    "        \n",
    "        self.stats['targets'] = ['Setosa', 'Versicolour', 'Virginica']\n",
    "        self.stats['targets_dict'] = {k: v for v, k in enumerate(self.stats['targets'])}\n",
    "\n",
    "        # Shuffle all the df_raw\n",
    "        df_raw = df_raw.sample(frac=1, random_state=5).reset_index(drop=True)\n",
    "        \n",
    "        # Preprocess data\n",
    "        df_raw.loc[:, 'sepal_length':'petal_width'] = self.preprocess(\n",
    "            df_raw.loc[:, 'sepal_length':'petal_width'])\n",
    "\n",
    "        # Split to training and testing data\n",
    "        n = df_raw.shape[0]\n",
    "        n_test = int(n * self.example_test_data_ratio)\n",
    "        training_data = df_raw.iloc[n_test:, :].reset_index(drop=True)\n",
    "        test_data = df_raw.iloc[:n_test, :].reset_index(drop=True)\n",
    "\n",
    "        # Split the data to features and labels\n",
    "        train_data_x = training_data.loc[:, 'sepal_length':'petal_width']\n",
    "        train_data_y = training_data['species']\n",
    "        test_data_x = test_data.loc[:, 'sepal_length':'petal_width']\n",
    "        test_data_y = test_data['species']\n",
    "\n",
    "        # When returning many variables, it is a good practice to give them names:\n",
    "        return {\n",
    "            'train_x':train_data_x,\n",
    "            'train_y':train_data_y,\n",
    "            'test_x':test_data_x,\n",
    "            'test_y':test_data_y,\n",
    "        }\n",
    "\n",
    "    def train_base_model(self, prepared_data: Dict[str, Any]) -> Any:\n",
    "        X, y = prepared_data['train_x'], prepared_data['train_y']\n",
    "        model = LogisticRegression(random_state=0)\n",
    "        model.fit(X, y)\n",
    "        return model\n",
    "    \n",
    "    def evaluate_model(self, data: Dict, model: MLModel) -> Dict:\n",
    "        super().evaluate_model(data, model)\n",
    "        X, y_true = data['test_x'], data['test_y']\n",
    "        y_pred = pd.Series(model.predict({'X': X, 'y': y_true})['species']).map(model.stats['targets_dict'])\n",
    "        return {'micro_f1_score': f1_score(y_true, y_pred, average='micro')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we define a `MLModel` with `process` method which will be used to generate prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMLModel(MLModel):\n",
    "    def preprocess(self, data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        raw_data = data['X']\n",
    "        return {\n",
    "            'X': self.stats['scaler'].transform(raw_data)\n",
    "        }\n",
    "\n",
    "    def process(self, input_data: dict) -> dict:\n",
    "        preprocess_data = self.preprocess(input_data)\n",
    "        y = self.base_model.predict(preprocess_data['X'])\n",
    "        return {'species': [self.stats['targets'][item] for item in y]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is the time to use our `MLModeler` and `MLModel` to create a classification model and generate prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'micro_f1_score': 0.3}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'species': ['Setosa', 'Versicolour']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_ml_modeler = MyMLModeler()\n",
    "my_ml_modeler.model_class = MyMLModel\n",
    "\n",
    "my_ml_model = my_ml_modeler.build_model()\n",
    "\n",
    "print(my_ml_model.metrics)\n",
    "\n",
    "prediction = my_ml_model.predict({\n",
    "    'X': pd.DataFrame(\n",
    "        [[5.1, 3.5, 1.5, 0.2],\n",
    "        [7.1, 3.5, 1.5, 0.6]], \n",
    "        columns=['sepal_length','sepal_width','petal_length','petal_width'])\n",
    "})\n",
    "prediction"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e4e6886837b24774dd32c84b9c87ed8ebf363b3b99a2777bd29883af915f606"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('h1st-efNXgVEL-py3.9': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
